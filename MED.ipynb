{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('x_train.gz')\n",
    "x_test = np.loadtxt('x_test.gz')\n",
    "y_train = np.loadtxt('y_train.gz')\n",
    "y_test = np.loadtxt('y_test.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=350)\n",
    "\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for MED model\n",
    "class MED:  \n",
    "    # Fit Function for the MED Model\n",
    "    def fit(self,x_train,y_train):\n",
    "        # initialize a list for category specimens\n",
    "        cat_specimen = []\n",
    "\n",
    "        # Save classification categories as a model attribute \n",
    "        self.categories = np.unique(y_train)\n",
    "\n",
    "        # Calculate the category Specimen using mean of the features of category samples\n",
    "        for cat in np.unique(y_train).tolist():\n",
    "            idx = (y_train==cat)\n",
    "            cat_samples = x_train[idx]\n",
    "            cat_specimen.append(cat_samples.mean(axis=0))\n",
    "\n",
    "        # Store category specimen as class attributes\n",
    "        self.cat_specimens = np.array(cat_specimen)\n",
    "    # Predict function for the MED model\n",
    "    def predict(self, x_test):\n",
    "        # Initialize a list for prediction results\n",
    "        predictions = []\n",
    "\n",
    "        # For each image calcute the distances from category specimens and make prediction using them\n",
    "        for image in x_test:\n",
    "            distances = [np.linalg.norm(self.cat_specimens[i]-image) for i in range(self.cat_specimens.shape[0])]\n",
    "            predictions.append(self.categories[np.argmin(distances)])\n",
    "\n",
    "        # store the predictions as class attribute and return the predictions\n",
    "        self.predictions = predictions\n",
    "        return predictions\n",
    "    # Prediction function to calculate prediction for one image (for internal test purposes)\n",
    "    def predictone(self, X):\n",
    "        # Calculate the distance from the category specimen\n",
    "        distances = [np.linalg.norm(self.cat_specimens[i]-X) for i in range(self.cat_specimens.shape[0])]\n",
    "\n",
    "        # Return the predicted class\n",
    "        return self.categories[np.argmin(distances)]\n",
    "    # Fuction to find the incorrectly categorized images (a replacement of confusion matrix for internal testing)\n",
    "    def error_vals(self,y_test):\n",
    "        # make a list of incorrectly identified test points and return them\n",
    "        errors = [(self.predictions[i],y_test[i]) for i in range(len(y_test)) if self.predictions[i] != y_test[i]]\n",
    "        return ([('prediction','y_val')] + errors)\n",
    "    # Function for plotting Decision Boundary in 2 Dimensions\n",
    "    def plot(self,x_train,y_train):\n",
    "        # Calculate the min and max value for each dimension\n",
    "        x_min, x_max = x_train[:, 0].min() - 100, x_train[:, 0].max() + 100\n",
    "        y_min, y_max = x_train[:, 1].min() - 100, x_train[:, 1].max() + 100\n",
    "\n",
    "        # Create a meshgrid using min and max values \n",
    "        # with intervals optimized for performance and fineness of boundary\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 10),np.arange(y_min, y_max, 10))\n",
    "\n",
    "        # Predictions to obtain the classification results\n",
    "        Z = np.array(self.predict(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n",
    "\n",
    "        # colour parameter labeling 0 as red and 1 as blue\n",
    "        col = ['b' if y_train[i] == 1 else 'r' for i in range(len(y_train))]\n",
    "\n",
    "        # Plotting of the boundary\n",
    "        plt.contourf(xx, yy, Z,colors =col, alpha=0.3)\n",
    "        plt.scatter(x_train[:, 0], x_train[:, 1], c=col, alpha=0.6, s=1)\n",
    "        plt.xlabel(\"Feature-1\")\n",
    "        plt.ylabel(\"Feature-2\")\n",
    "\n",
    "        # return the plt function to ease making customizations before plotting\n",
    "        return plt\n",
    "    # Function for calculating the parameters of MED Decision Boundary\n",
    "    def decision_boundary(self):\n",
    "        # Calculate the Constant in MED Decision Boundary\n",
    "        self.constant = (np.dot(self.cat_specimens[0],self.cat_specimens[0]) - np.dot(self.cat_specimens[1],self.cat_specimens[1]))/2\n",
    "        \n",
    "        # Calculate the Coefficients of variables in the Decision Boundary\n",
    "        self.coefficients = self.cat_specimens[0] - self.cat_specimens[1]\n",
    "\n",
    "        # Print the Decision Boundary\n",
    "        for i in range(self.cat_specimens.shape[1]):\n",
    "          print(f\"({self.coefficients[i]:+g})x{i+1}\",end=' ')\n",
    "        print(f\"{self.constant:+g} = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Prediction error using predictions and expected classification\n",
    "def prediction_accu(prediction, y_test):\n",
    "    if len(prediction) != len(y_test):\n",
    "        print(\"you are trying to get prediction of lists of unequal size\")\n",
    "        return 0\n",
    "    errors = sum([0 if prediction[i] != y_test[i] else 1 for i in range(len(y_test))])\n",
    "    return (errors/len(y_test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the confusion matrix using expected and predicted results\n",
    "def confusion_matrix(y_pred,y_test):\n",
    "    cm = np.empty([np.unique(y_test).shape[0],np.unique(y_test).shape[0]], dtype=int)\n",
    "    for cat in np.unique(y_test):\n",
    "        idx = (y_test==np.unique(y_test)[cat])\n",
    "        pred_event = np.array(y_pred)[idx]\n",
    "\n",
    "        cm[cat,1] = sum(pred_event)\n",
    "        cm[cat,0] = pred_event.shape[0] - cm[cat,1]\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.3972602739726"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_model = MED()\n",
    "med_model.fit(x_train,y_train)\n",
    "pred_med = med_model.predict(x_test)\n",
    "accu_med = prediction_accu(pred_med,y_test)\n",
    "accu_med"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "993f410c9306d6ef42b306fd54ae6229af7745664c20756624d393163e88c3fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
